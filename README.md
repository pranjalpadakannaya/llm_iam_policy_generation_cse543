# IAM Policy Generation and Security Compliance via Large Language Models in AWS Cloud Security Environments

This is a repo dedicated to the hosting of the artifacts, code and other resources related to the implementation aspect of our course CSE-543 taught by Dr. Stephen Yau.

## Repo Structure
```
llm_iam_policy_generation_cse543/
│
├── workflows/
│   └── iam-policy-evaluator.json         
│
├── docs/
│   ├── Report.pdf      ← will be added once ready (later this month as per Gantt Chart)
│
└── README.md                         ← main project documentation
```

## IAM Policy Generation & Validation Pipeline (n8n)

### Overview
This n8n workflow automates the generation, validation, and evaluation of AWS IAM policies using LLMs (OpenAI + Gemini + Anthropic) and a Lambda-backed simulator.

### Components
- Google Sheets integration for prompts & expected actions
- LLM generation (OpenAI GPT-4, Google Gemini, Anthropic)
- Lambda API call for IAM policy simulation
- Results write-back to Google Sheets

### How to run

1) Log in and create an account on n8n.io
2) Create a new workflow
3) Import workflow and select the json present in this repo

### Methodology


![WhatsApp Image 2025-11-02 at 22 20 41](https://github.com/user-attachments/assets/45506489-c979-493e-85a8-059afb2e8def)

#### Read Rows from Google Sheet
https://docs.google.com/spreadsheets/d/14Gy30B52cAMnQiROACOZmdF3c0Z600rJebO3YWBnlTg/edit?gid=0#gid=0

The above link redirects to a public google sheet which acts as the input source and output sink of this pipeline.

- *Column A* - Prompt: Natural Language Prompt
- *Column B* - Expected Actions: Expected action items i.e. truth output. This is what we should ideally get from the engine, in which case the experiment has succeeded.
- *Column C* - OPENAI policy: This is the output generated by the OpenAI Model
- *Column D* - OPENAI: This is the parsed output of the JSON generated by the OpenAI Model
- *Column E* - OPENAI Result: 4 possible values: ['Under-permissive','Over-permissive', 'Exactly Matching', 'Incomparable']
- *Column F* - GEMINI policy: This is the output generated by the Gemini Model
- *Column G* - GEMINI: This is the parsed output of the JSON generated by the Gemini Model
- *Column H* - GEMINI Result: 4 possible values: ['Under-permissive','Over-permissive', 'Exactly Matching', 'Incomparable']
- *Column I* - CLAUDE policy: This is the output generated by the Claude Model
- *Column J* - CLAUDE: This is the parsed output of the JSON generated by the Claude Model
- *Column K* - CLAUDE Result: 4 possible values: ['Under-permissive','Over-permissive', 'Exactly Matching', 'Incomparable']


#### AI Agent Subtask

This step consists of two parts

- Model Output
- Output Parser

#### Model Output:

n8n connects to the specific LLM model through API and secret keys of respective clients. Once this connection is setup, a *developer message* is setup in each of the respective LLMs. This developer message basically primes the model to produce the output in the format that we require, without adding anything extra and abstracting anything important.

Example of a developer message:

```
You are an expert in AWS Identity and Access Management (IAM) and must generate valid AWS IAM policies in JSON format that strictly follow least privilege principles.
Rules:
1.⁠ ⁠The model output must be a JSON object only — no text, no comments, no explanations.
2.⁠ ⁠Do exactly what the user prompt asks — nothing more.
3.⁠ ⁠Always apply AWS least privilege best practices — include only the minimal actions and resources necessary.
4.⁠ ⁠Use correct ARN patterns (e.g., "arn:aws:s3:::/" for all S3 objects, "*" only when absolutely required).
IMPORTANT RULE: Interpret the user prompt literally. If the user says “write access,” only include s3:PutObject (not multipart, delete, or versioned actions);  If the user says “read,” use only the minimal read actions like s3:GetObject; Do not assume additional permissions unless explicitly stated.
```
As seen, it will generate an output in line with the above requirements when the input is sent to the AI model through the pipeline

#### Output Parser

Since the model output is in JSON, we only want to compare the 'Action' item. This is because, if we were to compare policies, then it is not 100% guaranteed to have an exact match every single time even though the permissions are exactly matching. This is due to difference in values of the other items like Resources etc. Thus, the parser extracts only the Action keys and values from the JSON output and writes it to the google sheet

#### HTTP Request to IAM Simulator

Once the policy JSON is obtained from the LLM, it is sent to the IAM policy through a lambda function HTTP endpoint. Upon successful communication, the IAM simulator sends back the result in the form of 'Allow', 'Implicit Deny' and 'Explicity Deny' for each of the defined actions. We will then compare this against the source of truth

#### Write Output

Finally, at each step of the pipeline, the output is written back into the google sheet


